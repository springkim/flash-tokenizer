<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/FlashTokenizer_main_dark.png?raw=true">
    <img alt="FlashTokenizer" src="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/FlashTokenizer_main_light.png?raw=true" width=60%>
  </picture>
</p>
<h1 align="center">
The world's fastest CPU tokenizer library!
</h1>



## LLMæ¨è«–ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã®ãŸã‚ã®åŠ¹ç‡çš„ã§æœ€é©åŒ–ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³

[FlashTokenizer](https://pypi.org/project/flash-tokenizer/) ã¯ã€LLMæ¨è«–ã§ä½¿ç”¨ã•ã‚Œã‚‹BertTokenizerã‚’C++ã§å®Ÿè£…ã—ãŸ**é«˜æ€§èƒ½ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼**ã§ã™ã€‚[FlashAttention](https://github.com/Dao-AILab/flash-attention) ã‚„ [FlashInfer](https://github.com/flashinfer-ai/flashinfer) ã¨åŒæ§˜ã«ã€ã‚ã‚‰ã‚†ã‚‹ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ä¸­ã§æœ€é«˜ãƒ¬ãƒ™ãƒ«ã®é€Ÿåº¦ã¨ç²¾åº¦ã‚’èª‡ã‚Šã€transformersã®`BertTokenizerFast`ã‚ˆã‚Šã‚‚**10å€é«˜é€Ÿ**ã§ã™ã€‚


### [â–¶ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¢å‹•ç”»](https://www.youtube.com/watch?v=a_sTiAXeSE0)


> [!NOTE]  
> ### ãªãœã‹ï¼Ÿ
> - ç§ãŸã¡ã¯ã€[Huggingface ã® BertTokenizerFast](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/tokenization_bert_fast.py) ã‚ˆã‚Šã‚‚ **é«˜é€Ÿã§ã€ç²¾åº¦ãŒé«˜ãã€ä½¿ã„ã‚„ã™ã„ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶** ã‚’å¿…è¦ã¨ã—ã¦ã„ã¾ã™ã€‚([ãƒªãƒ³ã‚¯1](https://stackoverflow.com/questions/75595699/huggingfaces-berttokenizerfast-is-between-39000-and-258300-times-slower-than-ex), [ãƒªãƒ³ã‚¯2](https://github.com/PaddlePaddle/PaddleNLP/issues/8565), [ãƒªãƒ³ã‚¯3](https://blog.csdn.net/xhw205/article/details/129578988))
> - [PaddleNLP ã® BertTokenizerFast](https://paddlenlp.readthedocs.io/en/stable/_modules/paddlenlp/experimental/faster_tokenizer.html) ã¯ã€[Huggingface ã® Rust å®Ÿè£…](https://github.com/huggingface/tokenizers) ã‚’ `C++` ã«ç§»æ¤ã™ã‚‹ã“ã¨ã§ **1.2å€ã®æ€§èƒ½å‘ä¸Š** ã‚’é”æˆã—ã¾ã—ãŸã€‚ãŸã ã—ã€ä½¿ç”¨ã™ã‚‹ã«ã¯å·¨å¤§ãª [PaddlePaddle](https://github.com/PaddlePaddle/Paddle) ãŠã‚ˆã³ [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
> - [Tensorflow-text ã® FastBertTokenizer](https://www.tensorflow.org/text/api_docs/python/text/FastBertTokenizer) ã¯ã€å®Ÿéš›ã«ã¯ä»–ã¨æ¯”è¼ƒã—ã¦ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒåŠ£ã‚‹** çµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
> - [Microsoft ã® Blingfire](https://github.com/microsoft/BlingFire) ã¯ã€**ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’ã«8æ™‚é–“ä»¥ä¸Šã‹ã‹ã‚Š**ã€ç²¾åº¦ã‚‚ç›¸å¯¾çš„ã«ä½ã„ã§ã™ã€‚
> - [Rapid ã® cuDF](https://github.com/rapidsai/cudf) ã¯ GPU ãƒ™ãƒ¼ã‚¹ã® BertTokenizer ã‚’æä¾›ã—ã¾ã™ãŒã€**ç²¾åº¦ã®å•é¡Œ**ã‚’æŠ±ãˆã¦ã„ã¾ã™ã€‚
> - æ®‹å¿µãªãŒã‚‰ã€[FastBertTokenizer](https://github.com/georg-jung/FastBertTokenizer) ã‚„ [BertTokenizers](https://github.com/NMZivkovic/BertTokenizers) ã¯ `C#` ã§é–‹ç™ºã•ã‚Œã¦ãŠã‚Šã€`Python` ã§ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚
> 
> - ã“ã‚Œã‚‰ã®ç†ç”±ã‹ã‚‰ã€ç§ãŸã¡ã¯ **`FlashTokenizer` ã‚’é–‹ç™ºã—ã¾ã—ãŸ**ã€‚ã“ã‚Œã¯ `pip` ã§ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã€**ä¿å®ˆæ€§ã®é«˜ã„ C++ ã§é–‹ç™ºã•ã‚Œã¦ã„ã¾ã™**ã€‚ã•ã‚‰ã«ã€**éå¸¸ã«é«˜é€Ÿãªæ€§èƒ½ã‚’ä¿è¨¼**ã—ã¾ã™ã€‚ç§ãŸã¡ã®å®Ÿè£…ã¯ Blingfire ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã€ä½¿ã„ã‚„ã™ã•ã‚‚å‘ä¸Šã—ã¦ã„ã¾ã™ã€‚FlashTokenizer ã¯ã€[Fast WordPiece Tokenization](https://arxiv.org/abs/2012.15524) ã§ææ¡ˆã•ã‚ŒãŸ **LinMax Tokenizer** ã‚’ãƒ™ãƒ¼ã‚¹ã«å®Ÿè£…ã•ã‚Œã¦ãŠã‚Šã€**ç·šå½¢æ™‚é–“ã§ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º**ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€**C++ ãƒ¬ãƒ™ãƒ«ã§ã®ãƒãƒƒãƒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹ä¸¦åˆ—å‡¦ç†**ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€å“è¶Šã—ãŸã‚¹ãƒ”ãƒ¼ãƒ‰ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚
> 




<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/Banner_dark.png?raw=true">
    <img alt="Banner" src="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/Banner_light.png?raw=true" width=100%>
  </picture>
</p>


<p>
<img align="left" src="https://img.shields.io/badge/success-0B86F1?style=flat&logo=python&logoColor=white&label=MacOS_build">
<img align="left" src="https://img.shields.io/badge/success-0B86F1?style=flat&logo=python&logoColor=white&label=Windows_build">
<img align="left" src="https://img.shields.io/badge/success-0B86F1?style=flat&logo=python&logoColor=white&label=Linux_build">
</p><br>

* * *


### FlashTokenizerã«ã¯ä»¥ä¸‹ã®ä¸»è¦ãªæ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™
> [!TIP]
> 
> * C++17ã§å®Ÿè£…ã€‚
>   ***MacOS**: `clang++`ã€‚
>   ***Windows**: `Visual Studio 2022`ã€‚
>   ***Ubuntu**: `g++`ã€‚
>
> * pybind11ã‚’ä»‹ã—ã¦Pythonã§ã‚‚åŒæ§˜ã«é«˜é€Ÿã€‚
> * OPENMPã‚’ä½¿ç”¨ã—ãŸC++ãƒ¬ãƒ™ãƒ«ã§ã®ä¸¦åˆ—å‡¦ç†ã‚’ã‚µãƒãƒ¼ãƒˆã€‚
>



## ãƒ‹ãƒ¥ãƒ¼ã‚¹
> [!IMPORTANT]  
> **[2025å¹´4æœˆ2æ—¥]**
> - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ 
> - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯Pythonã‚’ä½¿ç”¨ã—ã¦å®Ÿæ–½ã•ã‚Œã€å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯[setup.sh](./perftest/setup.sh)ã‚’é€šã˜ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚
> - `BasicTokenizer`ã«`tokenize_early_stop`æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã‚ãšã‹ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’é”æˆã—ã¾ã—ãŸã€‚
> - [OpenMP](https://www.openmp.org/)ã¯Windowsã€Linuxã€macOSã™ã¹ã¦ã«ãŠã„ã¦`std::thread`ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸãŸã‚ã€OpenMPã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚
> 
> **[2025å¹´3æœˆ31æ—¥]**
> - å„OSç”¨ã®ãƒ“ãƒ«ãƒ‰æ¸ˆã¿whlãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚
>
> **[2025å¹´3æœˆ22æ—¥]**
>
> - AC Trieã«[DFA](https://blog.cloudflare.com/pt-br/making-waf-ai-models-go-brr/#:~:text=We%20can%20also%20tune%20Aho,settings%20based%20on%20this%20recommendation)ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚
>
> **[2025å¹´3æœˆ21æ—¥]**
> - ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ç²¾åº¦å‘ä¸Š
>
> **[2025å¹´3æœˆ19æ—¥]** 
> - [Ahoâ€“Corasick](https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm)ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‹ã‚‰LinMaxMatchingã‚’é©ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã¨ã‚ãšã‹ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€‚
> - ã™ã¹ã¦ã®é–¢æ•°ã®ãƒ–ãƒ©ãƒ³ãƒãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ”¹å–„ã—ã€å¼·åˆ¶ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã‚’é©ç”¨ã€‚
> - `WordpieceTokenizer(Backward)`ã®ä¸è¦ãªæ“ä½œã‚’å‰Šé™¤ã€‚
> - [Bloomãƒ•ã‚£ãƒ«ã‚¿ãƒ¼](https://en.wikipedia.org/wiki/Bloom_filter)ã‚’é™¤ã„ãŸã™ã¹ã¦ã®é–¢æ•°ã®æœ€é©åŒ–ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚ˆã‚Šã‚‚é«˜é€Ÿã€‚
> - `punctuation`ã€`control`ã€`whitespace`ã¯äº‹å‰ã«constexprã¨ã—ã¦å®šç¾©ã•ã‚Œã€Bloomãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
> - çµ±è¨ˆçš„ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šä¸è¦ãªãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã‚’å‰Šæ¸›ã€‚
> - âœ¨FlashTokenizerâœ¨ã§ã¯ã€`bert-base-uncased`ã¯å˜ä¸€ã‚³ã‚¢ã§1ç§’ã‚ãŸã‚Š**35K**ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã€ãƒ†ã‚­ã‚¹ãƒˆã‚ãŸã‚Šã®å‡¦ç†æ™‚é–“ã¯ç´„**28ns**ã§ã™ã€‚
>
> **[2025å¹´3æœˆ18æ—¥]** 
> - BasicTokenizerã®ç²¾åº¦å‘ä¸Šã«ã‚ˆã‚Šã€å…¨ä½“çš„ãªç²¾åº¦ãŒå‘ä¸Šã—ã€ç‰¹ã«Unicodeå…¥åŠ›ã«å¯¾ã—ã¦ã‚ˆã‚Šæ­£ç¢ºãªçµæœãŒå¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
>
> **[2025å¹´3æœˆ14æ—¥]** 
> - [Fast WordPiece Tokenization](https://arxiv.org/abs/2012.15524)ã§ç´¹ä»‹ã•ã‚ŒãŸ[Trie](https://en.wikipedia.org/wiki/Trie)ã‚’ä½¿ç”¨ã—ã¦ã€`WordPieceTokenizer`ã¨`WordPieceBackwordTokenizer`ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã¾ã—ãŸã€‚
> - SingleEncodingã§ã¯`std::list`ã«`FastPoolAllocator`ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã¾ã™ãŒã€ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ã¯ãªã„ãŸã‚ã€BatchEncodingã§ã¯`std::list<std::string>`ãŒãã®ã¾ã¾ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚BatchEncodingã§ã¯`OPENMP`ãŒå®Œå…¨ã«å‰Šé™¤ã•ã‚Œã€`std::thread`ã®ã¿ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
>
> **[2025å¹´3æœˆ10æ—¥]** 
> - robin_hoodã«ã‚ˆã‚‹é«˜é€Ÿãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°ã¨**std::list**ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ã®æœ€å°åŒ–ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€‚
>
>
> #### ãƒˆãƒ¼ã‚¯ãƒ³IDãƒãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
>
> ãƒˆãƒ¼ã‚¯ãƒ³ã¨IDã®ãƒãƒƒãƒ—ã«ã¯æœ€é€Ÿã®`robin_hood::unordered_flat_map<std::string, int>`ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚
>
> **[2025å¹´3æœˆ9æ—¥]** BertTokenizerç”¨ã®flash-tokenizerã®é–‹ç™ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚
> 



## 1. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
### å¿…è¦æ¡ä»¶
 * `Windows(AMD64)`, `MacOS(ARM64)`, `Ubuntu(x86-64)`ã€‚
 * `g++` / `clang++` / `MSVC`ã€‚
 * `python 3.8 ~ 3.13`ã€‚
### [PIP](https://pypi.org/project/flash-tokenizer/)ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
Windowsã§ã¯ã€[vc_redist.x64.exe](https://github.com/NLPOptimize/flash-tokenizer/releases/download/Packages/VC_redist.x64.exe)ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```bash
# Windows
pip install -U flash-tokenizer
```
```bash
# Linux
pip install -U flash-tokenizer
```
```bash
# MacOS
pip install -U flash-tokenizer
```

### ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
git clone https://github.com/NLPOptimize/flash-tokenizer
cd flash-tokenizer/prj
pip install .
```


## 2. ã‚µãƒ³ãƒ—ãƒ«

```python
from flash_tokenizer import BertTokenizerFlash
from transformers import BertTokenizer

titles = [
    'ç»ä¸èƒ½æ”¾å¼ƒï¼Œä¸–ç•Œä¸Šæ²¡æœ‰å¤±è´¥ï¼Œåªæœ‰æ”¾å¼ƒã€‚',
    'is there any doubt about it "None whatsoever"',
    "ì„¸ìƒ ì–´ë–¤ ì§ìŠ¹ì´ ì´ë¥¼ ë“œëŸ¬ë‚´ê³  ì‚¬ëƒ¥ì„ í•´? ì•½í•œ ì§ìŠ¹ì´ë‚˜ ëª¸ì„ ë¶€í’€ë¦¬ì§€, ì§„ì§œ ì§ìŠ¹ì€ ëˆ„êµ¬ë³´ë‹¤ ì¹¨ì°©í•˜ì§€.",
    'ãã®ã‚ˆã†ã«äºŒç•ªç›®ã«æ­»ã‚’å½è£…ã—ã¦ç”Ÿãæ®‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã‚¤ã‚¿ãƒ‰ãƒªãŒã©ã†ã—ã¦åˆã‚ã¦è¦‹ã‚‹è‡ªåˆ†ã‚’ã“ã‚“ãªã«æ°—é£ã£ã¦ãã‚Œã‚‹ã®ã‹ã¨å°‹ã­ã‚‹ã¨ã€Œç§ãŒå¤§åˆ‡ã«ã™ã‚‹äººãŸã¡ãŒã‚ãªãŸã‚’å¤§åˆ‡ã«ã™ã‚‹ã‹ã‚‰ã€ã¨ç­”ãˆã¦ã¯'
]

tokenizer1 = BertTokenizerFlash.from_pretrained('bert-base-multilingual-cased')
tokenizer2 = BertTokenizer.from_pretrained('bert-base-multilingual-cased')

correct = 0
for title in titles:
    print(title)
    tokens1 = tokenizer1.tokenize(title)
    tokens2 = tokenizer2.tokenize(title)
    ids1 = tokenizer1(title, max_length=512, padding="longest").input_ids[0]
    ids2 = tokenizer2(title, max_length=512, padding="longest", return_tensors="np").input_ids[0].tolist()
    if tokens1 == tokens2 and ids1 == ids2:
        correct += 1
        print("Accept!")
    else:
        print("Wrong Answer")
    print(ids1)
    print(ids2)
    print()

print(f'Accuracy: {correct * 100.0 / len(titles):.2f}%')
```

```
ç»ä¸èƒ½æ”¾å¼ƒï¼Œä¸–ç•Œä¸Šæ²¡æœ‰å¤±è´¥ï¼Œåªæœ‰æ”¾å¼ƒã€‚
Accept!
[101, 6346, 2080, 6546, 4284, 3704, 10064, 2087, 5621, 2078, 4917, 4461, 3204, 7480, 10064, 2751, 4461, 4284, 3704, 1882, 102]
[101, 6346, 2080, 6546, 4284, 3704, 10064, 2087, 5621, 2078, 4917, 4461, 3204, 7480, 10064, 2751, 4461, 4284, 3704, 1882, 102]

is there any doubt about it "None whatsoever"
Accept!
[101, 10124, 11155, 11178, 86697, 10978, 10271, 107, 86481, 12976, 11669, 23433, 107, 102]
[101, 10124, 11155, 11178, 86697, 10978, 10271, 107, 86481, 12976, 11669, 23433, 107, 102]

ì„¸ìƒ ì–´ë–¤ ì§ìŠ¹ì´ ì´ë¥¼ ë“œëŸ¬ë‚´ê³  ì‚¬ëƒ¥ì„ í•´? ì•½í•œ ì§ìŠ¹ì´ë‚˜ ëª¸ì„ ë¶€í’€ë¦¬ì§€, ì§„ì§œ ì§ìŠ¹ì€ ëˆ„êµ¬ë³´ë‹¤ ì¹¨ì°©í•˜ì§€.
Accept!
[101, 9435, 14871, 55910, 9710, 48210, 10739, 35756, 9113, 30873, 31605, 11664, 9405, 118729, 10622, 9960, 136, 9539, 11102, 9710, 48210, 43739, 9288, 10622, 9365, 119407, 12692, 12508, 117, 9708, 119235, 9710, 48210, 10892, 9032, 17196, 80001, 9783, 119248, 23665, 119, 102]
[101, 9435, 14871, 55910, 9710, 48210, 10739, 35756, 9113, 30873, 31605, 11664, 9405, 118729, 10622, 9960, 136, 9539, 11102, 9710, 48210, 43739, 9288, 10622, 9365, 119407, 12692, 12508, 117, 9708, 119235, 9710, 48210, 10892, 9032, 17196, 80001, 9783, 119248, 23665, 119, 102]

ãã®ã‚ˆã†ã«äºŒç•ªç›®ã«æ­»ã‚’å½è£…ã—ã¦ç”Ÿãæ®‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã‚¤ã‚¿ãƒ‰ãƒªãŒã©ã†ã—ã¦åˆã‚ã¦è¦‹ã‚‹è‡ªåˆ†ã‚’ã“ã‚“ãªã«æ°—é£ã£ã¦ãã‚Œã‚‹ã®ã‹ã¨å°‹ã­ã‚‹ã¨ã€Œç§ãŒå¤§åˆ‡ã«ã™ã‚‹äººãŸã¡ãŒã‚ãªãŸã‚’å¤§åˆ‡ã«ã™ã‚‹ã‹ã‚‰ã€ã¨ç­”ãˆã¦ã¯
Accept!
[101, 11332, 24273, 2150, 5632, 5755, 1943, 4805, 1980, 2371, 7104, 11592, 5600, 1913, 4814, 1975, 27969, 15970, 21462, 15713, 21612, 10898, 56910, 22526, 22267, 2547, 19945, 7143, 1975, 6621, 2534, 1980, 28442, 60907, 11312, 4854, 7770, 14813, 18825, 58174, 75191, 11662, 3456, 1945, 100812, 1890, 5949, 1912, 3197, 2535, 84543, 2179, 78776, 111787, 22946, 20058, 11377, 3197, 2535, 84543, 16867, 1891, 1940, 6076, 27144, 11588, 102]
[101, 11332, 24273, 2150, 5632, 5755, 1943, 4805, 1980, 2371, 7104, 11592, 5600, 1913, 4814, 1975, 27969, 15970, 21462, 15713, 21612, 10898, 56910, 22526, 22267, 2547, 19945, 7143, 1975, 6621, 2534, 1980, 28442, 60907, 11312, 4854, 7770, 14813, 18825, 58174, 75191, 11662, 3456, 1945, 100812, 1890, 5949, 1912, 3197, 2535, 84543, 2179, 78776, 111787, 22946, 20058, 11377, 3197, 2535, 84543, 16867, 1891, 1940, 6076, 27144, 11588, 102]

Accuracy: 100.00%
```

## 3. ä»–ã®å®Ÿè£…


<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/logos_dark.png">
    <img alt="Banner" src="./assets/logos_light.png" width=100%>
  </picture>
</p>


ã»ã¨ã‚“ã©ã®[BERT](https://arxiv.org/abs/1810.04805)ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¯[WordPiece Tokenizer](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf)ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€ãã®ã‚³ãƒ¼ãƒ‰ã¯[ã“ã¡ã‚‰](https://github.com/google-research/bert/blob/master/tokenization.py)ã§è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
ï¼ˆHuggingfaceã®ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ã¯[ã“ã¡ã‚‰](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/tokenization_bert.py)ã«ã‚ã‚Šã¾ã™ï¼‰ã€‚
BertTokenizerã¯CPUé›†ç´„å‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚‹ãŸã‚ã€æ¨è«–ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã€æœ€é©åŒ–ã•ã‚Œã¦ã„ãªã„ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¯éå¸¸ã«é…ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è‰¯ã„ä¾‹ã¨ã—ã¦[KR-BERT](https://arxiv.org/abs/2008.03979)ã§ç´¹ä»‹ã•ã‚ŒãŸ[BidirectionalWordpieceTokenizer](https://github.com/snunlp/KR-BERT/blob/master/krbert_tensorflow/tokenization_ranked.py)ãŒã‚ã‚Šã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®ã»ã¨ã‚“ã©ã¯åŒã˜ã§ã™ãŒã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã‚µãƒ–ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¾Œã‚å‘ãã«èµ°æŸ»ã—ã€å‰å‘ãã®èµ°æŸ»ã¨æ¯”è¼ƒã—ã¦ã‚ˆã‚Šå¤§ããªå€¤ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚è«–æ–‡ã§ã¯ç²¾åº¦å‘ä¸Šã‚’ä¸»å¼µã—ã¦ã„ã¾ã™ãŒã€ä»–ã®å®šé‡çš„ãªæŒ‡æ¨™ã‚’è¦‹ã¤ã‘ã‚‹ã®ã¯é›£ã—ãã€ç²¾åº¦å‘ä¸Šã¯é¡•è‘—ã§ã¯ãªãã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¯æ·±åˆ»ã«é…ããªã‚Šã¾ã™ã€‚
* transformersï¼ˆRustå®Ÿè£…ã€PyO3ï¼‰
* paddlenlpï¼ˆC++å®Ÿè£…ã€pybindï¼‰
* tensorflow-textï¼ˆC++å®Ÿè£…ã€pybindï¼‰
* blingfireï¼ˆC++å®Ÿè£…ã€ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒŠãƒªå‘¼ã³å‡ºã—ï¼‰
ã»ã¨ã‚“ã©ã®é–‹ç™ºè€…ã¯`transformers.BertTokenizer`ã¾ãŸã¯`transformers.AutoTokenizer`ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€`AutoTokenizer`ã‚’ä½¿ç”¨ã™ã‚‹ã¨`transformers.BertTokenizerFast`ãŒè¿”ã•ã‚Œã¾ã™ã€‚
å½“ç„¶ã€BertTokenizerã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã™ãŒã€çµæœã¯å®Œå…¨ã«åŒã˜ã§ã¯ãªã„ãŸã‚ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æ®µéšã‹ã‚‰100%ã®ç²¾åº¦ã‚’è«¦ã‚ã¦ã„ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚
BertTokenizerã¯transformersã ã‘ã§ãªãã€[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)ã‚„[tensorflow-text](https://www.tensorflow.org/text)ã§ã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚
ã¾ãŸã€Microsoftã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚Œã€ç¾åœ¨ã¯æ”¾æ£„ã•ã‚Œã¦ã„ã‚‹[Blingfire](https://github.com/microsoft/BlingFire)ã‚‚ã‚ã‚Šã¾ã™ã€‚
PaddleNLPã¯PaddlePaddleã‚’å¿…è¦ã¨ã—ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³3.0rcã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼æ©Ÿèƒ½ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™

```bash
##### Install PaddlePaddle, PaddleNLP
python -m pip install paddlepaddle==3.0.0b1 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/
pip install --upgrade paddlenlp==3.0.0b3
##### Install transformers
pip install transformers==4.47.1
##### Install tf-text
pip install tensorflow-text==2.18.1
##### Install blingfire
pip install blingfire
```


blingfireã‚’é™¤ã„ã¦ã€vocab.txtã ã‘ã‚ã‚Œã°ã™ãã«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚
ï¼ˆblingfireã‚‚vocab.txtã®ã¿ã‚’å¿…è¦ã¨ã—ã€8æ™‚é–“ã®å­¦ç¿’å¾Œã«ä½¿ç”¨ã§ãã¾ã™ï¼‰ã€‚
è©³ã—ãè¦‹ã¦ã„ãå®Ÿè£…ã¯`PaddleNLPã®BertTokenizerFast`ã¨`blingfire`ã§ã™ã€‚
* `blingfire`ï¼š[æ±ºå®šæ€§æœ‰é™çŠ¶æ…‹æ©Ÿæ¢°ï¼ˆDFSMï¼‰](https://github.com/microsoft/BlingFire/blob/master/doc/Bling_Fire_Tokenizer_Algorithms.pdf)ã‚’ä½¿ç”¨ã—ã¦1ã¤ã®ç·šå½¢ã‚¹ã‚­ãƒ£ãƒ³ã¨ä¸è¦ãªæ¯”è¼ƒã‚’æ’é™¤ã—ã€O(n)ã®æ™‚é–“ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯å°è±¡çš„ã§ã™ã€‚
  ***åˆ©ç‚¹**ï¼šä»–ã®å®Ÿè£…ã‚ˆã‚Šã‚‚**5ã€œ10å€é«˜é€Ÿ**ã€‚
  ***æ¬ ç‚¹**ï¼šé•·ã„å­¦ç¿’æ™‚é–“ï¼ˆ8æ™‚é–“ï¼‰ã¨ä»–ã®å®Ÿè£…ã‚ˆã‚Šã‚‚ä½ã„ç²¾åº¦ã€‚ï¼ˆ+äº‹å®Ÿä¸Šã®é–‹ç™ºä¸­æ–­ã«ã‚ˆã‚ŠåŠ©ã‘ã‚’å¾—ã‚‹ã®ãŒå›°é›£ï¼‰ã€‚
* `PaddleNLP`ï¼šä»¥ä¸‹ã®å®Ÿé¨“ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€PaddleNLPã¯å¸¸ã«BertTokenizerFastï¼ˆHFï¼‰ã¨åŒã˜å°æ•°ç‚¹ä»¥ä¸‹ã®æ¡æ•°ã§é«˜é€Ÿã§ã‚ã‚Šã€X86ã‹Armã‹ã«ã‹ã‹ã‚ã‚‰ãšã€ã©ã®OSã§ã‚‚å¸¸ã«é«˜é€Ÿã§ã™ã€‚
  ***åˆ©ç‚¹**ï¼š**å†…éƒ¨å®Ÿè£…ã¯C++ã§æ›¸ã‹ã‚Œã¦ã„ã¾ã™** Rustã§å®Ÿè£…ã•ã‚ŒãŸ`transformers.BertTokenizerFast`ã¨æ¯”è¼ƒã—ã¦ã€å®Œå…¨ã«åŒã˜å€¤ã‚’å‡ºåŠ›ã—ãªãŒã‚‰1.2å€é«˜é€Ÿã§ã™ã€‚
    * `return_tensors`ã§`pt(pytorch tensor)`ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ãŒã€ã“ã‚Œã¯å•é¡Œã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
  ***æ¬ ç‚¹**ï¼šPaddlePaddleã¨PaddleNLPã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ä»¥å¤–ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
  
  
## 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

### 4.1 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆå˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰

ç²¾åº¦ã¯[googleã®BertTokenizerFast](https://github.com/google-research/bert/blob/master/tokenization.py)ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦æ¸¬å®šã—ãŸçµæœã§ã™ã€‚`input_ids`ã®ã†ã¡1ã¤ã§ã‚‚ä¸æ­£ç¢ºã§ã‚ã‚Œã°ã€å›ç­”ã¯ä¸æ­£ç¢ºã¨ã¿ãªã•ã‚Œã¾ã™ã€‚


<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/comp_speed_dark.png">
    <img alt="FlashTokenizer" src="./assets/comp_speed_light.png" width=100%>
  </picture>
</p>

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/comp_accuracy_dark.png">
    <img alt="FlashTokenizer" src="./assets/comp_accuracy_light.png" width=100%>
  </picture>
</p>


### ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

#### [google-bert/bert-base-cased](https://huggingface.co/google-bert/bert-base-cased)

| Tokenizer                      | Elapsed Time | texts     | Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) | 84.3700s     | 1,000,000 | 99.9226% |
| BertTokenizerFast(PaddleNLP)   | 75.6551s     | 1,000,000 | 99.9226% |
| FastBertTokenizer(Tensorflow)  | 219.1259s    | 1,000,000 | 99.9160% |
| Blingfire                      | 13.6183s     | 1,000,000 | 99.8991% |
| **FlashBertTokenizer**             | 8.1968s      | 1,000,000 | 99.8216% |

#### [google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased)

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) |       91.7882s | 1,000,000 |   99.9326% |
| BertTokenizerFast(PaddleNLP)   |       83.6839s | 1,000,000 |   99.9326% |
| FastBertTokenizer(Tensorflow)  |      204.2240s | 1,000,000 |   99.1379% |
| Blingfire                      |       13.2374s | 1,000,000 |   99.8588% |
| **FlashBertTokenizer**             |        7.6313s | 1,000,000 |   99.6884% |

#### [google-bert/bert-base-multilingual-cased](https://huggingface.co/google-bert/bert-base-multilingual-cased)



| Tokenizer                      | Elapsed Time | texts     | Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) | 212.1570s    | 2,000,000 | 99.7964% |
| BertTokenizerFast(PaddleNLP)   | 193.9921s    | 2,000,000 | 99.7964% |
| FastBertTokenizer(Tensorflow)  | 394.1574s    | 2,000,000 | 99.7892% |
| Blingfire                      | 38.9013s     | 2,000,000 | 99.9780% |
| **FlashBertTokenizer**             | 20.4570s     | 2,000,000 | 99.8970% |


#### [beomi/kcbert-base](https://github.com/Beomi/KcBERT)

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) |       52.5744s | 1,000,000 |   99.6754% |
| BertTokenizerFast(PaddleNLP)   |       44.8943s | 1,000,000 |   99.6754% |
| FastBertTokenizer(Tensorflow)  |      198.0270s | 1,000,000 |   99.6639% |
| Blingfire                      |       13.0701s | 1,000,000 |   99.9434% |
| **FlashBertTokenizer**             |        5.2601s | 1,000,000 |   99.9484% |


| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------|-----------|------------|
| **FlashBertTokenizer**             |        5.1875s | 1,000,001 |   99.9484% |
| Blingfire                      |       13.2783s | 1,000,001 |   99.9435% |
| rust_tokenizers(guillaume-be)  |       16.6308s | 1,000,001 |   99.9829% |
| BertTokenizerFast(PaddleNLP)   |       44.5476s | 1,000,001 |   99.6754% |
| BertTokenizerFast(Huggingface) |       53.2525s | 1,000,001 |   99.6754% |
| FastBertTokenizer(Tensorflow)  |      202.1633s | 1,000,001 |   99.6639% |

#### [microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank](https://huggingface.co/microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank)

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) |      208.8858s | 2,000,000 |   99.7964% |
| BertTokenizerFast(PaddleNLP)   |      192.6593s | 2,000,000 |   99.7964% |
| FastBertTokenizer(Tensorflow)  |      413.2010s | 2,000,000 |   99.7892% |
| Blingfire                      |       39.3765s | 2,000,000 |   99.9780% |
| **FlashBertTokenizer**             |       22.8820s | 2,000,000 |   99.8970% |

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------|-----------|------------|
| **FlashBertTokenizer**             |       22.0901s | 2,000,001 |   99.8971% |
| Blingfire                      |       37.9836s | 2,000,001 |   99.9780% |
| rust_tokenizers(guillaume-be)  |       98.0366s | 2,000,001 |   99.9976% |
| BertTokenizerFast(PaddleNLP)   |      208.6889s | 2,000,001 |   99.7964% |
| BertTokenizerFast(Huggingface) |      219.2644s | 2,000,001 |   99.7964% |
| FastBertTokenizer(Tensorflow)  |      413.9725s | 2,000,001 |   99.7892% |

#### [KR-BERT](https://github.com/snunlp/KR-BERT)


| Tokenizer                                    |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerBidirectional(KR-BERT Original) |      128.3320s | 1,000,000 |  100.0000% |
| **FlashBertTokenizer(Bidirectional)**                           |       10.4492s | 1,000,000 |   99.9631% |



```mermaid
%%{ init: { "er" : { "layoutDirection" : "LR" } } }%%
erDiagram
    Text ||--o{ Preprocess : tokenize
    Preprocess o{--|| Inference : memcpy_h2d
    Inference o{--|| Postprocess : memcpy_d2h
```





## 6. äº’æ›æ€§

FlashBertTokenizerã¯ã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚å„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®äº’æ›æ€§ã‚‚LLMã®é«˜é€Ÿæ¨è«–ã«ã¯é‡è¦ã§ã™ã€‚
 * [PyTorch](https://pytorch.org/)ã¯condaã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ãªããªã‚Šã¾ã—ãŸã€‚
 * [ONNXRUNTIME](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#cuda-12x)ã¯CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚
 * PyTorchã‚‚æ–°ã—ã„CUDA 12.8ã‚’å„ªå…ˆã—ã¦CUDA 12.xã‚’æ”¾æ£„ã—ã‚ˆã†ã¨ã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã™ã¹ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§CUDA 11.8ã‚’ç¶­æŒã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚
   * CUDA 12.xã¯æœ€æ–°ã®GPUã€Hopperã¨Blackwellç”¨ã«ä½œã‚‰ã‚Œã¾ã—ãŸãŒã€Voltaã®ã‚ˆã†ãªGPUã§ã¯CUDA 11.8ã¯CUDA 12.xã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã™ã€‚



| DL Framework | Version | OS   | CPU  | CUDA 11.8 | CUDA 12.3 | CUDA 12.4 | CUDA 12.6 | CUDA 12.8 |
| ------------ | ----|---- | ---- | --------- | ----|----- | --------- | --------- |
| PyTorch | 2.6| Linux, Windows | âšª|âšª|âŒ|âšª| âšª |    âŒ      |
| PyTorch | 2.7|Linux, Windows|âšª|âšª|âŒ|âŒ|âšª|âšª|
| ONNXRUNTIME(11) | 1.20.x| Linux, Windows|âšª|âšª|âŒ|âŒ|âŒ|âŒ|
| ONNXRUNTIME(12) | 1.20.x| Linux, Windows|âšª|âŒ|âšª|âšª|âšª|âšª|
| PaddlePaddle | 3.0-beta | Linux, Windows|âšª|âšª|âŒ|âŒ|âŒ|âŒ|


## 7. GPUãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼

[Run State of the Art NLP Workloads at Scale with RAPIDS, HuggingFace, and Dask](https://developer.nvidia.com/blog/run-state-of-the-art-nlp-workloads-at-scale-with-rapids-huggingface-and-dask/#:~:text=,and%20then%20used%20in%20subsequent)ã«cuDFã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨å®Ÿè¡Œã®ä¾‹ãŒã‚ã‚Šã¾ã™ã€‚
*ï¼ˆã“ã‚Œã¯ä¿¡ã˜ã‚‰ã‚Œãªã„ã»ã©é«˜é€Ÿã§ã™ï¼‰*
[rapids(cudf)](https://docs.rapids.ai/)ä¸Šã§GPUã§WordPiece Tokenizerã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚
 * [å®Ÿè£…](https://github.com/rapidsai/cudf/blob/0e99ec3ec15b8b0ebe68bd884c7d22d600e9259e/python/cudf/cudf/core/wordpiece_tokenize.py#L10)
 * [ä¾‹](https://github.com/rapidsai/cudf/blob/0e99ec3ec15b8b0ebe68bd884c7d22d600e9259e/python/cudf/cudf/tests/text/test_subword_tokenizer.py#L244)
[rapidsã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•](https://docs.rapids.ai/install/)ã§ç¢ºèªã§ãã‚‹ã‚ˆã†ã«ã€Linuxã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ä»–ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨åŒã˜ã§ã¯ãªã„ãŸã‚ã€[docker](https://hub.docker.com/r/rapidsai/base)ãŒæœ€é©ãªé¸æŠã§ã™ã€‚ã“ã‚Œã¯ãƒãƒƒãƒå‡¦ç†ã§ã¯CPUã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã™ãŒã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã§ã¯CPUã‚ˆã‚Šã‚‚é…ã„ã§ã™ã€‚
[ãƒ–ãƒ­ã‚°](https://developer.nvidia.com/blog/run-state-of-the-art-nlp-workloads-at-scale-with-rapids-huggingface-and-dask/#:~:text=,and then used in subsequent)ã«ã¯è‰¯ã„ä¾‹ã®ã‚³ãƒ¼ãƒ‰ã¨èª¬æ˜ãŒã‚ã‚Šã¾ã™ã€‚cuDFã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ã¾ãšä»¥ä¸‹ã®ã‚ˆã†ã«vocab.txtã‚’[hash_vocab](https://github.com/rapidsai/cudf/blob/branch-25.06/python/cudf/cudf/utils/hash_vocab_utils.py)ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å•é¡Œã¯ã€hash_vocabé–¢æ•°ãŒå¤šè¨€èªã‚’å¤‰æ›ã§ããªã„ã“ã¨ã§ã™ã€‚ã—ãŸãŒã£ã¦ã€vocabå†…ã«è‹±èª/ä¸­å›½èªä»¥å¤–ã®æ–‡å­—ãŒã‚ã‚‹å ´åˆã€cuDFã®WordpieceTokenizerã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚

```python
import cudf
from cudf.utils.hash_vocab_utils import hash_vocab
hash_vocab('bert-base-cased-vocab.txt', 'voc_hash.txt')
```





## TODO

- [x] [BidirectionalWordPieceTokenizer](https://github.com/snunlp/KR-BERT/blob/master/krbert_tensorflow/tokenization_ranked.py)
- [x] BatchEncoder with Multithreading. 
- [x] Replace `std::list` to `boost::intrusive::list`.
- [x] ~~[MaxMatch-Dropout: Subword Regularization for WordPiece](https://arxiv.org/abs/2209.04126) Option.~~
- [x] Use stack memory for reduce memory allocation. (C-Style, [alloca](https://man7.org/linux/man-pages/man3/alloca.3.html), [_alloca](https://learn.microsoft.com/ko-kr/cpp/c-runtime-library/reference/alloca?view=msvc-170))
- [x] ~~Support for parallel processing option for single encode.~~
- [ ] `circle.ai`
  - [ ] Implement distribution of compiled wheel packages for installation.
- [ ] SIMD
- [ ] ~~CUDA Version.~~



## è¬è¾

FlashTokenizerã¯[FlashAttention](https://github.com/Dao-AILab/flash-attention)ã€[FlashInfer](https://github.com/flashinfer-ai/flashinfer)ã€[FastBertTokenizer](https://github.com/georg-jung/FastBertTokenizer)ãŠã‚ˆã³[tokenizers-cpp](https://github.com/mlc-ai/tokenizers-cpp)ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ã¦ã„ã¾ã™ã€‚



## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

* **WordPiece**
  * ğŸ“’ [huggingface/tokenizers (Rust)](https://github.com/huggingface/tokenizers)
    * transformers.BertTokenizerFastã®Rustå®Ÿè£…ã§ã€Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚
    * ğŸ”µ **Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚**
  * ğŸ”¥ [FastBertTokenizer (C#)](https://fastberttokenizer.gjung.com)
    * ä¿¡ã˜ã‚‰ã‚Œãªã„ã»ã©é«˜é€Ÿãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã™ãŒã€éè‹±èªã‚¯ã‚¨ãƒªã®ç²¾åº¦ã¯å¤§å¹…ã«ä½ä¸‹ã—ã¾ã™ã€‚
  * âŒ [BertTokenizers (C#)](https://github.com/NMZivkovic/BertTokenizers)
    * [FastBertTokenizer (C#) VS BertTokenizers (C#)](https://github.com/georg-jung/FastBertTokenizer/tree/master?tab=readme-ov-file#comparison-to-berttokenizers)ã‹ã‚‰`FastBertTokenizer(C#)`ãŒã‚ˆã‚Šé«˜é€Ÿã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚
  * ğŸ”¥ [rust-tokenizers (Rust)](https://github.com/guillaume-be/rust-tokenizers)
    * BertTokenizerFlashã¨Blingfireã‚ˆã‚Šã¯é…ã„ã§ã™ãŒã€ä»–ã®å®Ÿè£…ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ç²¾åº¦ãŒé«˜ã„ã§ã™ã€‚
    * ğŸ”µ **Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚**
  * âŒ [tokenizers-cpp (C++)](https://github.com/mlc-ai/tokenizers-cpp)
    * `tokenizer-cpp`ã¯SentencePieceã¨HuggingFaceã®Rustå®Ÿè£…ã®ãƒ©ãƒƒãƒ‘ãƒ¼ãªã®ã§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯æ„å‘³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
  * âŒ [bertTokenizer (Java)](https://github.com/ankiteciitkgp/bertTokenizer)
    * Javaã¯ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
  * âœ… [ZhuoruLin/fast-wordpiece (Rust)](https://github.com/ZhuoruLin/fast-wordpiece)
    * LinMaxMatchingã‚’ä½¿ç”¨ã—ãŸRustå®Ÿè£…ã§ã€Rustã§ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã‚ã‚Šã€C++å®Ÿè£…ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã¯ãªã„ã¨äºˆæƒ³ã•ã‚Œã¾ã™ã€‚
  * âŒ [huggingface_tokenizer_cpp (C++)](https://github.com/Sorrow321/huggingface_tokenizer_cpp)
    * å˜ç´”ãªC++å®Ÿè£…ã®ãŸã‚éå¸¸ã«é…ã„ã§ã™ã€‚
  * âŒ [SeanLee97/BertWordPieceTokenizer.jl (Julia)](https://github.com/SeanLee97/BertWordPieceTokenizer.jl)
    * Juliaã¯ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
* **BPE**
  * https://github.com/openai/tiktoken
* **SentencePiece**
  * [google/sentencepiece (C++)](https://github.com/google/sentencepiece)



## â­ æ­´å²

<a href="https://www.star-history.com/#NLPOptimize/flash-tokenizer&Date">

 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=NLPOptimize/flash-tokenizer&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=NLPOptimize/flash-tokenizer&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=NLPOptimize/flash-tokenizer&type=Date" />
 </picture>
</a>


## ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

* https://medium.com/@techhara/which-bert-tokenizer-is-faster-b832aa978b46
* https://medium.com/@atharv6f_47401/wordpiece-tokenization-a-bpe-variant-73cc48865cbf
* https://www.restack.io/p/transformer-models-bert-answer-fast-berttokenizerfast-cat-ai
* https://medium.com/@anmolkohli/my-notes-on-bert-tokenizer-and-model-98dc22d0b64
* https://nocomplexity.com/documents/fossml/nlpframeworks.html
* https://github.com/martinus/robin-hood-hashing
* https://arxiv.org/abs/2012.15524
* https://github.com/google/highway
