<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/FlashTokenizer_main_dark.png?raw=true">
    <img alt="FlashTokenizer" src="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/FlashTokenizer_main_light.png?raw=true" width=60%>
  </picture>
</p>
<h1 align="center">
ä¸–ç•Œä¸Šæœ€å¿«çš„ CPU tokenizer åº“ï¼
</h1>


## é’ˆå¯¹ LLM æ¨ç†æœåŠ¡çš„é«˜æ•ˆä¼˜åŒ– Tokenizer å¼•æ“



[FlashTokenizer](https://pypi.org/project/flash-tokenizer/) æ˜¯ä¸€ä¸ªç”¨äºLLMæ¨ç†çš„**é«˜æ€§èƒ½BertTokenizerçš„C++å®ç°**ã€‚å®ƒåœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢é¢†å…ˆäºå…¶ä»–æ‰€æœ‰åˆ†è¯å™¨ï¼Œç±»ä¼¼äº[FlashAttention](https://github.com/Dao-AILab/flash-attention) å’Œ [FlashInfer](https://github.com/flashinfer-ai/flashinfer)ï¼Œç›¸æ¯”äºtransformersåº“ä¸­çš„`BertTokenizerFast`å¿«äº†**10å€**ã€‚



> [!NOTE]  
> ### ä¸ºä»€ä¹ˆï¼Ÿ
> - æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ¯” [Huggingface çš„ BertTokenizerFast](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/tokenization_bert_fast.py) æ›´å¿«ã€æ›´å‡†ç¡®ã€æ›´æ˜“ç”¨çš„åˆ†è¯å™¨ï¼ˆ[é“¾æ¥1](https://stackoverflow.com/questions/75595699/huggingfaces-berttokenizerfast-is-between-39000-and-258300-times-slower-than-ex)ã€[é“¾æ¥2](https://github.com/PaddlePaddle/PaddleNLP/issues/8565)ã€[é“¾æ¥3](https://blog.csdn.net/xhw205/article/details/129578988)ï¼‰ã€‚
> - [PaddleNLP çš„ BertTokenizerFast](https://paddlenlp.readthedocs.io/en/stable/_modules/paddlenlp/experimental/faster_tokenizer.html) é€šè¿‡å°† [Huggingface çš„ Rust ç‰ˆæœ¬](https://github.com/huggingface/tokenizers) åœ¨`C++`ä¸­é‡æ–°å®ç°ï¼Œæ€§èƒ½æé«˜äº†çº¦ 1.2 å€ã€‚ä½†ä½¿ç”¨å®ƒéœ€è¦åŒæ—¶å®‰è£…åºå¤§çš„ [PaddlePaddle](https://github.com/PaddlePaddle/Paddle) å’Œ [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) è½¯ä»¶åŒ…ã€‚
> - [Tensorflow-text çš„ FastBertTokenizer](https://www.tensorflow.org/text/api_docs/python/text/FastBertTokenizer) å®é™…æ€§èƒ½æ›´æ…¢ã€‚
> - [å¾®è½¯çš„ Blingfire](https://github.com/microsoft/BlingFire) åœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šçš„è®­ç»ƒ**éœ€è¦è¶…è¿‡8å°æ—¶**ï¼Œå¹¶ä¸”å‡†ç¡®æ€§ç›¸å¯¹è¾ƒä½ã€‚
> - [Rapid çš„ cuDF](https://github.com/rapidsai/cudf) æä¾›äº†åŸºäº GPU çš„ BertTokenizerï¼Œä½†å­˜åœ¨å‡†ç¡®æ€§é—®é¢˜ã€‚
> - é—æ†¾çš„æ˜¯ï¼Œ[FastBertTokenizer](https://github.com/georg-jung/FastBertTokenizer) å’Œ [BertTokenizers](https://github.com/NMZivkovic/BertTokenizers) æ˜¯ç”¨`C#`å¼€å‘çš„ï¼Œæ— æ³•åœ¨`Python`ä¸­ä½¿ç”¨ã€‚

> - è¿™å°±æ˜¯æˆ‘ä»¬å¼€å‘ `FlashTokenizer` çš„åŸå› ã€‚å®ƒèƒ½é€šè¿‡`pip`è½»æ¾å®‰è£…ï¼Œå¹¶ä¸”æ˜¯ç”¨`C++`å¼€å‘çš„ï¼Œä¾¿äºç›´æ¥ç»´æŠ¤ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜ä¿è¯äº†æå¿«çš„é€Ÿåº¦ã€‚æˆ‘ä»¬å®ç°äº†ä¸€ä¸ªæ¯” Blingfire æ›´å¿«ã€æ›´æ˜“ç”¨çš„åˆ†è¯å™¨ã€‚FlashTokenizer åŸºäºè®ºæ–‡ [Fast WordPiece Tokenization](https://arxiv.org/abs/2012.15524) ä¸­æå‡ºçš„**LinMax Tokenizer**ï¼Œå®ç°çº¿æ€§æ—¶é—´å¤æ‚åº¦çš„åˆ†è¯ã€‚åŒæ—¶å®ƒåœ¨`C++`çº§åˆ«ä¸Šæ”¯æŒ**æ‰¹é‡ç¼–ç çš„å¹¶è¡Œå¤„ç†**ï¼Œèƒ½å¤Ÿæä¾›å“è¶Šçš„æ€§èƒ½ã€‚




<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/Banner_dark.png?raw=true">
    <img alt="Banner" src="https://github.com/NLPOptimize/flash-tokenizer/blob/main/assets/Banner_light.png?raw=true" width=100%>
  </picture>
</p>


<p>
<img align="left" src="https://img.shields.io/badge/success-0B86F1?style=flat&logo=python&logoColor=white&label=MacOS_build">
<img align="left" src="https://img.shields.io/badge/success-0B86F1?style=flat&logo=python&logoColor=white&label=Windows_build">
<img align="left" src="https://img.shields.io/badge/success-0B86F1?style=flat&logo=python&logoColor=white&label=Linux_build">
</p><br>

* * *

### FlashTokenizer åŒ…å«ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

> [!TIP]
>
> * ä½¿ç”¨ C++17 å®ç°ã€‚
>   * **MacOS**ï¼šä½¿ç”¨ `clang++`ã€‚
>   * **Windows**ï¼šä½¿ç”¨ `Visual Studio 2022`ã€‚
>   * **Ubuntu**ï¼šä½¿ç”¨ `g++`ã€‚
>
> * é€šè¿‡ pybind11 åœ¨ Python ä¸­åŒæ ·æ‹¥æœ‰é«˜é€Ÿè¡¨ç°ã€‚
> * åœ¨ C++ å±‚é¢åˆ©ç”¨ OPENMP æ”¯æŒå¹¶è¡Œå¤„ç†ã€‚ 



##  æ–°é—»

> [!IMPORTANT]  
> **ã€2025å¹´4æœˆ2æ—¥ã€‘**
> - æ·»åŠ æ€§èƒ½åŸºå‡†æµ‹è¯•ä»£ç ã€‚
> - æ€§èƒ½åŸºå‡†æµ‹è¯•é‡‡ç”¨ Python è¿›è¡Œï¼Œæ‰€éœ€çš„è½¯ä»¶åŒ…å¯é€šè¿‡ [setup.sh](./perftest/setup.sh) å®‰è£…ã€‚
> - ä¸º `BasicTokenizer` å¢åŠ äº† `tokenize_early_stop` åŠŸèƒ½ï¼Œç•¥å¾®æå‡äº†æ€§èƒ½ã€‚
> - åœ¨ Windowsã€Linux å’Œ macOS ä¸Šï¼Œ[OpenMP](https://www.openmp.org/) çš„æ€§èƒ½å‡ä¼˜äº `std::thread`ï¼Œå› æ­¤å…¨é¢åˆ‡æ¢ä¸ºä½¿ç”¨ OpenMPã€‚
> 
> **ã€2025å¹´3æœˆ31æ—¥ã€‘**
> - æä¾›äº†å„ä¸ªæ“ä½œç³»ç»Ÿçš„é¢„æ„å»º whl æ–‡ä»¶ã€‚
>
> **ã€2025å¹´3æœˆ22æ—¥ã€‘**
> - å°† [DFA](https://blog.cloudflare.com/pt-br/making-waf-ai-models-go-brr/#:~:text=We%20can%20also%20tune%20Aho,settings%20based%20on%20this%20recommendation) åŠ å…¥ AC Trie ä¸­ã€‚
>
> **ã€2025å¹´3æœˆ21æ—¥ã€‘**
> - æ”¹è¿›åˆ†è¯å™¨çš„å‡†ç¡®æ€§ã€‚
>
> **ã€2025å¹´3æœˆ19æ—¥ã€‘**
> - ä½¿ç”¨ [Ahoâ€“Corasick ç®—æ³•](https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm) ä¸­çš„ LinMaxMatchingï¼Œé™ä½äº†å†…å­˜å ç”¨ï¼Œå¹¶ç•¥å¾®æé«˜äº†æ€§èƒ½ã€‚
> - æ”¹è¿›æ‰€æœ‰å‡½æ•°çš„åˆ†æ”¯æµæ°´çº¿å¹¶å¼ºåˆ¶å†…è”ï¼ˆforce-inlineï¼‰ã€‚
> - ç§»é™¤äº† `WordpieceTokenizer(Backward)` ä¸­ä¸å¿…è¦çš„æ“ä½œã€‚
> - ä¼˜åŒ–äº†é™¤ [å¸ƒéš†è¿‡æ»¤å™¨ (Bloom filter)](https://en.wikipedia.org/wiki/Bloom_filter) ä»¥å¤–çš„æ‰€æœ‰å‡½æ•°ï¼Œæ€§èƒ½æ¯”ç¼“å­˜æ›´å¿«ã€‚
> - å°† `punctuation`ã€`control` å’Œ `whitespace` é¢„å…ˆå®šä¹‰ä¸º constexprï¼Œå¹¶ä½œä¸ºå¸ƒéš†è¿‡æ»¤å™¨ä½¿ç”¨ã€‚
> - é€šè¿‡ç»Ÿè®¡å†…å­˜åˆ†æå‡å°‘ä¸å¿…è¦çš„å†…å­˜åˆ†é…ã€‚
> - åœ¨ âœ¨FlashTokenizerâœ¨ ä¸­ï¼Œ`bert-base-uncased` åœ¨å•æ ¸ä¸Šæ¯ç§’å¯å¤„ç†çº¦ **35K** æ¡æ–‡æœ¬ï¼Œæ¯æ¡æ–‡æœ¬çš„å¤„ç†æ—¶é—´çº¦ä¸º **28 çº³ç§’**ã€‚
>
> **ã€2025å¹´3æœˆ18æ—¥ã€‘**
> - æ”¹è¿›äº† BasicTokenizer çš„å‡†ç¡®æ€§ï¼Œæ•´ä½“åˆ†è¯å‡†ç¡®æ€§æå‡ï¼Œå°¤å…¶å¯¹äº Unicode è¾“å…¥çš„å‡†ç¡®æ€§æ˜¾è‘—æé«˜ã€‚
>
> **ã€2025å¹´3æœˆ14æ—¥ã€‘**
> - é€šè¿‡åœ¨ `WordPieceTokenizer` å’Œ `WordPieceBackwardTokenizer` ä¸­ä½¿ç”¨ [Trie](https://en.wikipedia.org/wiki/Trie) æ•°æ®ç»“æ„ï¼ˆæ¥è‡ª [Fast WordPiece Tokenization](https://arxiv.org/abs/2012.15524) è®ºæ–‡ï¼‰ï¼Œå¤§å¹…æå‡äº†æ€§èƒ½ã€‚
> - åœ¨ SingleEncoding ä¸­ä½¿ç”¨ `FastPoolAllocator` æ”¹è¿›äº† `std::list` çš„æ€§èƒ½ï¼Œä½†è¯¥æ–¹æ³•çº¿ç¨‹ä¸å®‰å…¨ï¼Œå› æ­¤ BatchEncoding ä¸­ç»§ç»­ä½¿ç”¨åŸç”Ÿ `std::list<std::string>`ã€‚åŒæ—¶ï¼ŒBatchEncoding ä¸­å®Œå…¨ç§»é™¤ OPENMPï¼Œä»…ä½¿ç”¨ `std::thread`ã€‚
>
> **ã€2025å¹´3æœˆ10æ—¥ã€‘**
> - ä½¿ç”¨ robin_hood ä¼˜åŒ– token æ˜ å°„é€Ÿåº¦ï¼ŒåŒæ—¶é‡‡ç”¨ `std::list` é™ä½å†…å­˜æ‹·è´ï¼Œæå‡æ€§èƒ½ã€‚
>
> #### Token Ids æ˜ å°„è¡¨æ€§èƒ½æµ‹è¯•ï¼š
>
> Token å’Œ Ids çš„æ˜ å°„è¡¨ä½¿ç”¨äº†æ€§èƒ½æœ€ä¼˜çš„ `robin_hood::unordered_flat_map<std::string, int>`ã€‚
>
> **ã€2025å¹´3æœˆ9æ—¥ã€‘**
> å®Œæˆäº†é€‚ç”¨äº BertTokenizer çš„ flash-tokenizer çš„å¼€å‘å·¥ä½œã€‚


## 1. å®‰è£…æ–¹æ³•

### ç³»ç»Ÿéœ€æ±‚
* æ“ä½œç³»ç»Ÿï¼š`Windows(AMD64)`ã€`MacOS(ARM64)`ã€`Ubuntu(x86-64)`ã€‚
* ç¼–è¯‘å™¨ï¼š`g++` / `clang++` / `MSVC`ã€‚
* Pythonç‰ˆæœ¬ï¼š`Python 3.8 ~ 3.13`ã€‚

### é€šè¿‡ [PIP](https://pypi.org/project/flash-tokenizer/) å®‰è£…


åœ¨ Windows ä¸Šï¼Œä½ éœ€è¦å®‰è£… [vc_redist.x64.exe](https://github.com/NLPOptimize/flash-tokenizer/releases/download/Packages/VC_redist.x64.exe)ã€‚
```bash
# Windows
pip install -U flash-tokenizer
```
```bash
# Linux
pip install -U flash-tokenizer
```
```bash
# MacOS
pip install -U flash-tokenizer
```

### ä»æºä»£ç å®‰è£…
```bash
git clone https://github.com/NLPOptimize/flash-tokenizer
cd flash-tokenizer/prj
pip install .
```


## 2. ç¤ºä¾‹

```python
from flash_tokenizer import BertTokenizerFlash
from transformers import BertTokenizer

titles = [
    'ç»ä¸èƒ½æ”¾å¼ƒï¼Œä¸–ç•Œä¸Šæ²¡æœ‰å¤±è´¥ï¼Œåªæœ‰æ”¾å¼ƒã€‚',
    'is there any doubt about it "None whatsoever"',
    "ì„¸ìƒ ì–´ë–¤ ì§ìŠ¹ì´ ì´ë¥¼ ë“œëŸ¬ë‚´ê³  ì‚¬ëƒ¥ì„ í•´? ì•½í•œ ì§ìŠ¹ì´ë‚˜ ëª¸ì„ ë¶€í’€ë¦¬ì§€, ì§„ì§œ ì§ìŠ¹ì€ ëˆ„êµ¬ë³´ë‹¤ ì¹¨ì°©í•˜ì§€.",
    'ãã®ã‚ˆã†ã«äºŒç•ªç›®ã«æ­»ã‚’å½è£…ã—ã¦ç”Ÿãæ®‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã‚¤ã‚¿ãƒ‰ãƒªãŒã©ã†ã—ã¦åˆã‚ã¦è¦‹ã‚‹è‡ªåˆ†ã‚’ã“ã‚“ãªã«æ°—é£ã£ã¦ãã‚Œã‚‹ã®ã‹ã¨å°‹ã­ã‚‹ã¨ã€Œç§ãŒå¤§åˆ‡ã«ã™ã‚‹äººãŸã¡ãŒã‚ãªãŸã‚’å¤§åˆ‡ã«ã™ã‚‹ã‹ã‚‰ã€ã¨ç­”ãˆã¦ã¯'
]

tokenizer1 = BertTokenizerFlash.from_pretrained('bert-base-multilingual-cased')
tokenizer2 = BertTokenizer.from_pretrained('bert-base-multilingual-cased')

correct = 0
for title in titles:
    print(title)
    tokens1 = tokenizer1.tokenize(title)
    tokens2 = tokenizer2.tokenize(title)
    ids1 = tokenizer1(title, max_length=512, padding="longest").input_ids[0]
    ids2 = tokenizer2(title, max_length=512, padding="longest", return_tensors="np").input_ids[0].tolist()
    if tokens1 == tokens2 and ids1 == ids2:
        correct += 1
        print("Accept!")
    else:
        print("Wrong Answer")
    print(ids1)
    print(ids2)
    print()

print(f'Accuracy: {correct * 100.0 / len(titles):.2f}%')
```

```
ç»ä¸èƒ½æ”¾å¼ƒï¼Œä¸–ç•Œä¸Šæ²¡æœ‰å¤±è´¥ï¼Œåªæœ‰æ”¾å¼ƒã€‚
Accept!
[101, 6346, 2080, 6546, 4284, 3704, 10064, 2087, 5621, 2078, 4917, 4461, 3204, 7480, 10064, 2751, 4461, 4284, 3704, 1882, 102]
[101, 6346, 2080, 6546, 4284, 3704, 10064, 2087, 5621, 2078, 4917, 4461, 3204, 7480, 10064, 2751, 4461, 4284, 3704, 1882, 102]

is there any doubt about it "None whatsoever"
Accept!
[101, 10124, 11155, 11178, 86697, 10978, 10271, 107, 86481, 12976, 11669, 23433, 107, 102]
[101, 10124, 11155, 11178, 86697, 10978, 10271, 107, 86481, 12976, 11669, 23433, 107, 102]

ì„¸ìƒ ì–´ë–¤ ì§ìŠ¹ì´ ì´ë¥¼ ë“œëŸ¬ë‚´ê³  ì‚¬ëƒ¥ì„ í•´? ì•½í•œ ì§ìŠ¹ì´ë‚˜ ëª¸ì„ ë¶€í’€ë¦¬ì§€, ì§„ì§œ ì§ìŠ¹ì€ ëˆ„êµ¬ë³´ë‹¤ ì¹¨ì°©í•˜ì§€.
Accept!
[101, 9435, 14871, 55910, 9710, 48210, 10739, 35756, 9113, 30873, 31605, 11664, 9405, 118729, 10622, 9960, 136, 9539, 11102, 9710, 48210, 43739, 9288, 10622, 9365, 119407, 12692, 12508, 117, 9708, 119235, 9710, 48210, 10892, 9032, 17196, 80001, 9783, 119248, 23665, 119, 102]
[101, 9435, 14871, 55910, 9710, 48210, 10739, 35756, 9113, 30873, 31605, 11664, 9405, 118729, 10622, 9960, 136, 9539, 11102, 9710, 48210, 43739, 9288, 10622, 9365, 119407, 12692, 12508, 117, 9708, 119235, 9710, 48210, 10892, 9032, 17196, 80001, 9783, 119248, 23665, 119, 102]

ãã®ã‚ˆã†ã«äºŒç•ªç›®ã«æ­»ã‚’å½è£…ã—ã¦ç”Ÿãæ®‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã‚¤ã‚¿ãƒ‰ãƒªãŒã©ã†ã—ã¦åˆã‚ã¦è¦‹ã‚‹è‡ªåˆ†ã‚’ã“ã‚“ãªã«æ°—é£ã£ã¦ãã‚Œã‚‹ã®ã‹ã¨å°‹ã­ã‚‹ã¨ã€Œç§ãŒå¤§åˆ‡ã«ã™ã‚‹äººãŸã¡ãŒã‚ãªãŸã‚’å¤§åˆ‡ã«ã™ã‚‹ã‹ã‚‰ã€ã¨ç­”ãˆã¦ã¯
Accept!
[101, 11332, 24273, 2150, 5632, 5755, 1943, 4805, 1980, 2371, 7104, 11592, 5600, 1913, 4814, 1975, 27969, 15970, 21462, 15713, 21612, 10898, 56910, 22526, 22267, 2547, 19945, 7143, 1975, 6621, 2534, 1980, 28442, 60907, 11312, 4854, 7770, 14813, 18825, 58174, 75191, 11662, 3456, 1945, 100812, 1890, 5949, 1912, 3197, 2535, 84543, 2179, 78776, 111787, 22946, 20058, 11377, 3197, 2535, 84543, 16867, 1891, 1940, 6076, 27144, 11588, 102]
[101, 11332, 24273, 2150, 5632, 5755, 1943, 4805, 1980, 2371, 7104, 11592, 5600, 1913, 4814, 1975, 27969, 15970, 21462, 15713, 21612, 10898, 56910, 22526, 22267, 2547, 19945, 7143, 1975, 6621, 2534, 1980, 28442, 60907, 11312, 4854, 7770, 14813, 18825, 58174, 75191, 11662, 3456, 1945, 100812, 1890, 5949, 1912, 3197, 2535, 84543, 2179, 78776, 111787, 22946, 20058, 11377, 3197, 2535, 84543, 16867, 1891, 1940, 6076, 27144, 11588, 102]

Accuracy: 100.00%
```

## 3. å…¶ä»–å®ç°æ–¹å¼


<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/logos_dark.png">
    <img alt="Banner" src="./assets/logos_light.png" width=100%>
  </picture>
</p>


å¤§å¤šæ•°åŸºäº [BERT](https://arxiv.org/abs/1810.04805) çš„æ¨¡å‹ä½¿ç”¨ [WordPiece Tokenizer](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf)ï¼Œå…¶ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/google-research/bert/blob/master/tokenization.py)æ‰¾åˆ°ã€‚
ï¼ˆHuggingface æä¾›çš„ç®€å•å®ç°å¯å‚è€ƒ[è¿™é‡Œ](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/tokenization_bert.py)ï¼‰ã€‚

ç”±äº BertTokenizer æ˜¯ä¸€ç§CPUå¯†é›†å‹ç®—æ³•ï¼Œæ¨ç†å¯èƒ½ä¼šæˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œæœªç»ä¼˜åŒ–çš„ tokenizer å¯èƒ½ä¼šéå¸¸ç¼“æ…¢ã€‚ä¸€ä¸ªå…¸å‹çš„ä¾‹å­æ˜¯[KR-BERT](https://arxiv.org/abs/2008.03979)æå‡ºçš„[BidirectionalWordpieceTokenizer](https://github.com/snunlp/KR-BERT/blob/master/krbert_tensorflow/tokenization_ranked.py)ã€‚è™½ç„¶å¤§éƒ¨åˆ†ä»£ç ä¸åŸç‰ˆç›¸åŒï¼Œä½†è¯¥ç®—æ³•ä¼šé€†å‘éå†å­è¯ï¼Œå¹¶å†™å…¥æ¯”æ­£å‘éå†æ›´å¤§çš„å€¼ã€‚è®ºæ–‡å£°ç§°å…¶å‡†ç¡®æ€§æœ‰æ‰€æé«˜ï¼Œä½†å¾ˆéš¾æ‰¾åˆ°å…¶ä»–é‡åŒ–æŒ‡æ ‡ï¼Œå®é™…å‡†ç¡®æ€§æå‡ä¹Ÿå¹¶ä¸æ˜¾è‘—ï¼ŒåŒæ—¶ tokenizer çš„è¿è¡Œé€Ÿåº¦ä¹Ÿæ˜æ˜¾é™ä½äº†ã€‚

ç°æœ‰å®ç°åŒ…æ‹¬ï¼š

* transformersï¼ˆRust å®ç°ï¼ŒPyO3 å°è£…ï¼‰
* paddlenlpï¼ˆC++ å®ç°ï¼Œpybind å°è£…ï¼‰
* tensorflow-textï¼ˆC++ å®ç°ï¼Œpybind å°è£…ï¼‰
* blingfireï¼ˆC++ å®ç°ï¼ŒåŸç”ŸäºŒè¿›åˆ¶è°ƒç”¨ï¼‰

å¤šæ•°å¼€å‘è€…é€šå¸¸ä¼šä½¿ç”¨ `transformers.BertTokenizer` æˆ– `transformers.AutoTokenizer`ï¼Œä½†ä½¿ç”¨ `AutoTokenizer` å®é™…ä¸Šä¼šè¿”å› `transformers.BertTokenizerFast`ã€‚

æ˜¾ç„¶ï¼Œ`BertTokenizerFast` æ¯”åŸç‰ˆçš„ BertTokenizer æ›´å¿«ï¼Œä½†ä¸¤è€…çš„ç»“æœå¹¶éå®Œå…¨ä¸€è‡´ï¼Œè¿™æ„å‘³ç€ä½¿ç”¨æ›´å¿«çš„å®ç°å·²ç»æ”¾å¼ƒäº† 100% çš„å‡†ç¡®æ€§ã€‚

æ­¤å¤–ï¼ŒBertTokenizer å¹¶éä»…ç”± transformers æä¾›ã€‚[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) å’Œ [tensorflow-text](https://www.tensorflow.org/text) ä¹Ÿæä¾›äº†è‡ªå·±çš„ BertTokenizer å®ç°ã€‚

å¦å¤–è¿˜æœ‰ç”±å¾®è½¯å¼€å‘çš„[Blingfire](https://github.com/microsoft/BlingFire)ï¼Œä½†è¯¥é¡¹ç›®ç›®å‰å·²ç»è¢«æ”¾å¼ƒã€‚

PaddleNLP éœ€è¦å®‰è£… PaddlePaddleï¼Œå¹¶ä» 3.0rc ç‰ˆæœ¬å¼€å§‹æä¾› tokenizer åŠŸèƒ½ã€‚ä½ å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ–¹å¼å®‰è£…ï¼š

```bash
##### Install PaddlePaddle, PaddleNLP
python -m pip install paddlepaddle==3.0.0b1 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/
pip install --upgrade paddlenlp==3.0.0b3
##### Install transformers
pip install transformers==4.47.1
##### Install tf-text
pip install tensorflow-text==2.18.1
##### Install blingfire
pip install blingfire
```


é™¤äº† Blingfire å¤–ï¼Œåªéœ€è¦ä¸€ä¸ª `vocab.txt` æ–‡ä»¶ï¼Œå°±å¯ä»¥ç«‹å³ä½¿ç”¨å…¶ä»–æ‰€æœ‰ tokenizerã€‚
ï¼ˆBlingfire ä¹Ÿåªéœ€ `vocab.txt`ï¼Œä½†éœ€è¦ç»è¿‡8å°æ—¶çš„è®­ç»ƒåæ‰èƒ½ä½¿ç”¨ã€‚ï¼‰

ä¸‹é¢æˆ‘ä»¬å°†è¯¦ç»†ä»‹ç» `PaddleNLP çš„ BertTokenizerFast` å’Œ `Blingfire` çš„å®ç°ã€‚

* **Blingfire**: ä½¿ç”¨[ç¡®å®šæ€§æœ‰é™çŠ¶æ€æœº (DFSM)](https://github.com/microsoft/BlingFire/blob/master/doc/Bling_Fire_Tokenizer_Algorithms.pdf)ï¼Œçœå»ä¸€æ¬¡çº¿æ€§æ‰«æå’Œä¸å¿…è¦çš„æ¯”è¾ƒï¼Œæ—¶é—´å¤æ‚åº¦è¾¾åˆ° O(n)ï¼Œæ€§èƒ½éå¸¸å‡ºè‰²ã€‚
  * **ä¼˜ç‚¹**ï¼šæ¯”å…¶ä»–å®ç°å¿« **5-10å€**ã€‚
  * **ç¼ºç‚¹**ï¼šè®­ç»ƒæ—¶é—´è¿‡é•¿ï¼ˆ8å°æ—¶ï¼‰ï¼Œä¸”å‡†ç¡®æ€§æ¯”å…¶ä»–å®ç°ç¨ä½ã€‚æ­¤å¤–ï¼Œç”±äºé¡¹ç›®å®é™…ä¸Šå·²åœæ­¢å¼€å‘ï¼Œè·å–æ”¯æŒå›°éš¾ã€‚

* **PaddleNLP**: å¦‚ä¸‹é¢å®éªŒæ‰€ç¤ºï¼Œåœ¨ä»»ä½•æ“ä½œç³»ç»Ÿä¸Šï¼ˆæ— è®ºæ˜¯ X86 æˆ– Armï¼‰ï¼ŒPaddleNLP å§‹ç»ˆæ¯” Huggingface çš„ BertTokenizerFast æ›´å¿«ï¼Œä¸”ç²¾åº¦ç›¸åŒï¼ˆåˆ°å°æ•°ç‚¹åçš„æ•°å€¼å‡ä¸€è‡´ï¼‰ã€‚
  * **ä¼˜ç‚¹**ï¼š
    * **å†…éƒ¨ä½¿ç”¨ C++ å®ç°**ï¼Œç›¸æ¯”äº Huggingface ä½¿ç”¨ Rust å®ç°çš„ `transformers.BertTokenizerFast`ï¼Œé€Ÿåº¦å¿« 1.2 å€ï¼Œä¸”è¾“å‡ºç»“æœå®Œå…¨ä¸€è‡´ã€‚
    * è™½ç„¶ä¸èƒ½åœ¨ `return_tensors` ä¸­æŒ‡å®š `ptï¼ˆPyTorch Tensorï¼‰`ï¼Œä½†è¿™å¹¶éå®é™…é—®é¢˜ã€‚
  * **ç¼ºç‚¹**ï¼šéœ€è¦é¢å¤–å®‰è£… PaddlePaddle å’Œ PaddleNLP è½¯ä»¶åŒ…ï¼Œé™¤æ­¤ä¹‹å¤–æ²¡æœ‰å…¶ä»–ç¼ºç‚¹ã€‚

## 4. æ€§èƒ½æµ‹è¯•

### 4.1 æ€§èƒ½æµ‹è¯•ï¼ˆå•æ¡æ–‡æœ¬ç¼–ç ï¼‰

å‡†ç¡®æ€§ä»¥ [Google çš„ BertTokenizerFast](https://github.com/google-research/bert/blob/master/tokenization.py) ä¸ºåŸºå‡†è¿›è¡Œæµ‹é‡ã€‚å¦‚æœ`input_ids`ä¸­å­˜åœ¨ä»»ä½•ä¸€ä¸ªé”™è¯¯ï¼Œåˆ™è§†ä¸ºç»“æœä¸å‡†ç¡®ã€‚


<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/comp_speed_dark.png">
    <img alt="FlashTokenizer" src="./assets/comp_speed_light.png" width=100%>
  </picture>
</p>

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/comp_accuracy_dark.png">
    <img alt="FlashTokenizer" src="./assets/comp_accuracy_light.png" width=100%>
  </picture>
</p>


### Tokenizer æ€§èƒ½æ¯”è¾ƒ

#### [google-bert/bert-base-chinese](https://huggingface.co/google-bert/bert-base-chinese)

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------|-----------|------------|
| FlashBertTokenizer             |       12.4959s | 1,000,000 |   99.5057% |
| Blingfire                      |       18.9008s | 1,000,000 |   61.1254% |
| rust_tokenizers(guillaume-be)  |       57.4387s | 1,000,000 |   99.9957% |
| BertTokenizerFast(PaddleNLP)   |      143.5012s | 1,000,000 |   99.1475% |
| BertTokenizerFast(Huggingface) |      152.8926s | 1,000,000 |   99.1475% |


ä»¥ä¸‹æ˜¯åœ¨ `.Net9` ä¸­è¿è¡Œ [FastBertTokenizer (C#)](https://fastberttokenizer.gjung.com) å’Œåœ¨ C++ ä¸­è¿è¡Œ FlashBertTokenizer çš„ç»“æœã€‚FlashBertTokenizer åœ¨ä¸­æ–‡ä¸Šå±•ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ã€‚


| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------|-----------|------------|
|FastBertTokenizer (C#)|21.9430s|2000001|66.4466%|
|FlashBertTokenizer (C++) | 10.6592s | 2000001|99.9002%|



#### [google-bert/bert-base-cased](https://huggingface.co/google-bert/bert-base-cased)

| Tokenizer                      | Elapsed Time | texts     | Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) | 84.3700s     | 1,000,000 | 99.9226% |
| BertTokenizerFast(PaddleNLP)   | 75.6551s     | 1,000,000 | 99.9226% |
| FastBertTokenizer(Tensorflow)  | 219.1259s    | 1,000,000 | 99.9160% |
| Blingfire                      | 13.6183s     | 1,000,000 | 99.8991% |
| **FlashBertTokenizer**             | 8.1968s      | 1,000,000 | 99.8216% |

#### [google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased)

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) |       91.7882s | 1,000,000 |   99.9326% |
| BertTokenizerFast(PaddleNLP)   |       83.6839s | 1,000,000 |   99.9326% |
| FastBertTokenizer(Tensorflow)  |      204.2240s | 1,000,000 |   99.1379% |
| Blingfire                      |       13.2374s | 1,000,000 |   99.8588% |
| **FlashBertTokenizer**             |        7.6313s | 1,000,000 |   99.6884% |

#### [google-bert/bert-base-multilingual-cased](https://huggingface.co/google-bert/bert-base-multilingual-cased)



| Tokenizer                      | Elapsed Time | texts     | Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) | 212.1570s    | 2,000,000 | 99.7964% |
| BertTokenizerFast(PaddleNLP)   | 193.9921s    | 2,000,000 | 99.7964% |
| FastBertTokenizer(Tensorflow)  | 394.1574s    | 2,000,000 | 99.7892% |
| Blingfire                      | 38.9013s     | 2,000,000 | 99.9780% |
| **FlashBertTokenizer**             | 20.4570s     | 2,000,000 | 99.8970% |


#### [beomi/kcbert-base](https://github.com/Beomi/KcBERT)

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) |       52.5744s | 1,000,000 |   99.6754% |
| BertTokenizerFast(PaddleNLP)   |       44.8943s | 1,000,000 |   99.6754% |
| FastBertTokenizer(Tensorflow)  |      198.0270s | 1,000,000 |   99.6639% |
| Blingfire                      |       13.0701s | 1,000,000 |   99.9434% |
| **FlashBertTokenizer**             |        5.2601s | 1,000,000 |   99.9484% |


| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------|-----------|------------|
| **FlashBertTokenizer**             |        5.1875s | 1,000,001 |   99.9484% |
| Blingfire                      |       13.2783s | 1,000,001 |   99.9435% |
| rust_tokenizers(guillaume-be)  |       16.6308s | 1,000,001 |   99.9829% |
| BertTokenizerFast(PaddleNLP)   |       44.5476s | 1,000,001 |   99.6754% |
| BertTokenizerFast(Huggingface) |       53.2525s | 1,000,001 |   99.6754% |
| FastBertTokenizer(Tensorflow)  |      202.1633s | 1,000,001 |   99.6639% |

#### [microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank](https://huggingface.co/microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank)

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------:|-----------:|------------:|
| BertTokenizerFast(Huggingface) |      208.8858s | 2,000,000 |   99.7964% |
| BertTokenizerFast(PaddleNLP)   |      192.6593s | 2,000,000 |   99.7964% |
| FastBertTokenizer(Tensorflow)  |      413.2010s | 2,000,000 |   99.7892% |
| Blingfire                      |       39.3765s | 2,000,000 |   99.9780% |
| **FlashBertTokenizer**             |       22.8820s | 2,000,000 |   99.8970% |

| Tokenizer                      |   Elapsed Time |     texts |   Accuracy |
|--------------------------------|----------------|-----------|------------|
| **FlashBertTokenizer**             |       22.0901s | 2,000,001 |   99.8971% |
| Blingfire                      |       37.9836s | 2,000,001 |   99.9780% |
| rust_tokenizers(guillaume-be)  |       98.0366s | 2,000,001 |   99.9976% |
| BertTokenizerFast(PaddleNLP)   |      208.6889s | 2,000,001 |   99.7964% |
| BertTokenizerFast(Huggingface) |      219.2644s | 2,000,001 |   99.7964% |
| FastBertTokenizer(Tensorflow)  |      413.9725s | 2,000,001 |   99.7892% |




```mermaid
%%{ init: { "er" : { "layoutDirection" : "LR" } } }%%
erDiagram
    Text ||--o{ Preprocess : tokenize
    Preprocess o{--|| Inference : memcpy_h2d
    Inference o{--|| Postprocess : memcpy_d2h
```





## 6. å…¼å®¹æ€§

FlashBertTokenizer å¯ä»¥ä¸ä»»ä½•æ¡†æ¶ä¸€èµ·ä½¿ç”¨ã€‚å„æ¡†æ¶çš„ CUDA ç‰ˆæœ¬å…¼å®¹æ€§å¯¹äº LLM çš„å¿«é€Ÿæ¨ç†ä¹Ÿè‡³å…³é‡è¦ã€‚

* [PyTorch](https://pytorch.org/) å·²ä¸å†æ”¯æŒé€šè¿‡ conda å®‰è£…ã€‚
* [ONNXRUNTIME](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#cuda-12x) æ ¹æ® CUDA ç‰ˆæœ¬è¿›è¡Œäº†åŒºåˆ†ã€‚
* PyTorch ä¹Ÿåœ¨è€ƒè™‘æ”¾å¼ƒ CUDA 12.xï¼Œè½¬è€Œä½¿ç”¨æ›´æ–°çš„ CUDA 12.8ã€‚ä½†æ•´ä½“è¶‹åŠ¿ä»ç„¶æ˜¯å„ä¸ªæ¡†æ¶æ™®éä¿ç•™å¯¹ CUDA 11.8 çš„æ”¯æŒã€‚
  * CUDA 12.x æ˜¯ä¸“ä¸ºæœ€æ–°çš„ Hopper å’Œ Blackwell GPU å¼€å‘çš„ï¼Œè€Œåœ¨åƒ Volta ç­‰è¾ƒæ—©çš„ GPU ä¸Šï¼ŒCUDA 11.8 æ¯” CUDA 12.x æ›´å¿«ã€‚



| DL Framework | Version | OS   | CPU  | CUDA 11.8 | CUDA 12.3 | CUDA 12.4 | CUDA 12.6 | CUDA 12.8 |
| ------------ | ----|---- | ---- | --------- | ----|----- | --------- | --------- |
| PyTorch | 2.6| Linux, Windows | âšª|âšª|âŒ|âšª| âšª |    âŒ      |
| PyTorch | 2.7|Linux, Windows|âšª|âšª|âŒ|âŒ|âšª|âšª|
| ONNXRUNTIME(11) | 1.20.x| Linux, Windows|âšª|âšª|âŒ|âŒ|âŒ|âŒ|
| ONNXRUNTIME(12) | 1.20.x| Linux, Windows|âšª|âŒ|âšª|âšª|âšª|âšª|
| PaddlePaddle | 3.0-beta | Linux, Windows|âšª|âšª|âŒ|âŒ|âŒ|âŒ|


## 7. GPU Tokenizer

ä¸‹é¢æ˜¯åœ¨ [Run State of the Art NLP Workloads at Scale with RAPIDS, HuggingFace, and Dask](https://developer.nvidia.com/blog/run-state-of-the-art-nlp-workloads-at-scale-with-rapids-huggingface-and-dask/#:~:text=,and%20then%20used%20in%20subsequent) ä¸­å®‰è£…å’Œè¿è¡Œ cuDF çš„ç¤ºä¾‹ã€‚  
*(é€Ÿåº¦éå¸¸å¿«)*

ä½ å¯ä»¥ä½¿ç”¨ [rapids(cuDF)](https://docs.rapids.ai/) åœ¨ GPU ä¸Šè¿è¡Œ WordPiece Tokenizerã€‚

 * [å…·ä½“å®ç°ä»£ç ](https://github.com/rapidsai/cudf/blob/0e99ec3ec15b8b0ebe68bd884c7d22d600e9259e/python/cudf/cudf/core/wordpiece_tokenize.py#L10)
 * [ä½¿ç”¨ç¤ºä¾‹ä»£ç ](https://github.com/rapidsai/cudf/blob/0e99ec3ec15b8b0ebe68bd884c7d22d600e9259e/python/cudf/cudf/tests/text/test_subword_tokenizer.py#L244)

å¦‚ [rapids å®‰è£…æŒ‡å—](https://docs.rapids.ai/install/) æ‰€ç¤ºï¼Œç›®å‰ rapids ä»…æ”¯æŒ Linuxï¼Œä¸” CUDA ç‰ˆæœ¬ä¸å…¶ä»–æ¡†æ¶ä¸å®Œå…¨ä¸€è‡´ï¼Œå› æ­¤æ¨èä½¿ç”¨ [docker é•œåƒ](https://hub.docker.com/r/rapidsai/base)ã€‚  
ä½¿ç”¨ GPU åœ¨æ‰¹å¤„ç†æ—¶æ¯” CPU å¿«ï¼Œä½†åœ¨æµå¼å¤„ç†ï¼ˆå•æ¡æ•°æ®ï¼‰æ—¶å´æ¯” CPU æ…¢ã€‚

[NVIDIA çš„å®˜æ–¹åšå®¢](https://developer.nvidia.com/blog/run-state-of-the-art-nlp-workloads-at-scale-with-rapids-huggingface-and-dask/#:~:text=,and then used in subsequent) ä¸­æä¾›äº†è¯¦ç»†çš„ç¤ºä¾‹ä»£ç å’Œè¯´æ˜ã€‚  
ä½¿ç”¨ cuDF å‰ï¼Œå¿…é¡»å…ˆå°† `vocab.txt` è½¬æ¢æˆå¦‚ä¸‹æ‰€ç¤ºçš„ [hash_vocab](https://github.com/rapidsai/cudf/blob/branch-25.06/python/cudf/cudf/utils/hash_vocab_utils.py)ã€‚  
ä½†å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼Œè¯¥ `hash_vocab` è½¬æ¢å‡½æ•°å¹¶ä¸æ”¯æŒå¤šè¯­è¨€ã€‚å› æ­¤ï¼Œå¦‚æœä½ çš„è¯è¡¨ä¸­åŒ…å«è‹±è¯­å’Œä¸­æ–‡ä»¥å¤–çš„å…¶ä»–å­—ç¬¦ï¼ŒcuDF çš„ WordPieceTokenizer å°†æ— æ³•ä½¿ç”¨ã€‚

```python
import cudf
from cudf.utils.hash_vocab_utils import hash_vocab
hash_vocab('bert-base-cased-vocab.txt', 'voc_hash.txt')
```





## å¾…åŠäº‹é¡¹ï¼ˆTODOï¼‰

- [x] [BidirectionalWordPieceTokenizer](https://github.com/snunlp/KR-BERT/blob/master/krbert_tensorflow/tokenization_ranked.py)
- [x] æ”¯æŒå¤šçº¿ç¨‹çš„ BatchEncoder
- [x] å°† `std::list` æ›¿æ¢ä¸º `boost::intrusive::list`
- [x] ~~[MaxMatch-Dropout: Subword Regularization for WordPiece](https://arxiv.org/abs/2209.04126) é€‰é¡¹~~
- [x] ä½¿ç”¨æ ˆå†…å­˜ä»¥å‡å°‘å†…å­˜åˆ†é…ï¼ˆCé£æ ¼ï¼Œ[alloca](https://man7.org/linux/man-pages/man3/alloca.3.html)ï¼Œ[_alloca](https://learn.microsoft.com/ko-kr/cpp/c-runtime-library/reference/alloca?view=msvc-170)ï¼‰
- [x] ~~ä¸ºå•æ¡ç¼–ç æä¾›å¹¶è¡Œå¤„ç†é€‰é¡¹~~
- [ ] `circle.ai`
  - [ ] å®ç°ç¼–è¯‘åçš„ wheel åŒ…åˆ†å‘ä¸å®‰è£…
- [ ] SIMD æ”¯æŒ
- [ ] CUDA ç‰ˆæœ¬



## è‡´è°¢

FlashTokenizer çš„å¼€å‘çµæ„Ÿæ¥æºäº [FlashAttention](https://github.com/Dao-AILab/flash-attention)ã€[FlashInfer](https://github.com/flashinfer-ai/flashinfer)ã€[FastBertTokenizer](https://github.com/georg-jung/FastBertTokenizer) ä»¥åŠ [tokenizers-cpp](https://github.com/mlc-ai/tokenizers-cpp) ç­‰é¡¹ç›®ã€‚



## æ€§èƒ½æ¯”è¾ƒ

* **WordPiece**
  * ğŸ“’ [huggingface/tokenizers (Rust)](https://github.com/huggingface/tokenizers)
    * transformers.BertTokenizerFast çš„ Rust å®ç°ï¼Œä»¥ Python åŒ…æä¾›ã€‚
    * ğŸ”µ **ä»¥ Python åŒ…å½¢å¼æä¾›ã€‚**
  * ğŸ”¥ [FastBertTokenizer (C#)](https://fastberttokenizer.gjung.com)
    * æ€§èƒ½æå¿«ï¼Œä½†éè‹±æ–‡æŸ¥è¯¢çš„å‡†ç¡®æ€§æ˜¾è‘—é™ä½ã€‚
  * âŒ [BertTokenizers (C#)](https://github.com/NMZivkovic/BertTokenizers)
    * ä» [FastBertTokenizer (C#) VS BertTokenizers (C#)](https://github.com/georg-jung/FastBertTokenizer/tree/master?tab=readme-ov-file#comparison-to-berttokenizers) çš„æ¯”è¾ƒå¯ç¡®è®¤ï¼Œ`FastBertTokenizer(C#)` æ›´å¿«ã€‚
  * ğŸ”¥ [rust-tokenizers (Rust)](https://github.com/guillaume-be/rust-tokenizers)
    * é€Ÿåº¦æ…¢äº BertTokenizerFlash å’Œ Blingfireï¼Œä½†æ¯”å…¶ä»–å®ç°æ›´å¿«ã€æ›´å‡†ç¡®ã€‚
    * ğŸ”µ **ä»¥ Python åŒ…å½¢å¼æä¾›ã€‚**
  * âŒ [tokenizers-cpp (C++)](https://github.com/mlc-ai/tokenizers-cpp)
    * åªæ˜¯ SentencePiece å’Œ HuggingFace Rust å®ç°çš„å°è£…ï¼Œæ€§èƒ½æµ‹è¯•æ— å®é™…æ„ä¹‰ã€‚
  * âŒ [bertTokenizer (Java)](https://github.com/ankiteciitkgp/bertTokenizer)
    * Java å®ç°æœªçº³å…¥æ¯”è¾ƒèŒƒå›´ã€‚
  * âœ… [ZhuoruLin/fast-wordpiece (Rust)](https://github.com/ZhuoruLin/fast-wordpiece)
    * ä½¿ç”¨ LinMaxMatching çš„ Rust å®ç°ï¼Œä»…é™ Rust ç¯å¢ƒï¼Œæ€§èƒ½é¢„è®¡ä¸ä¼šè¶…è¿‡ C++ å®ç°ã€‚
  * âŒ [huggingface_tokenizer_cpp (C++)](https://github.com/Sorrow321/huggingface_tokenizer_cpp)
    * æœ´ç´ çš„ C++ å®ç°ï¼Œæ€§èƒ½éå¸¸ç¼“æ…¢ã€‚
  * âŒ [SeanLee97/BertWordPieceTokenizer.jl (Julia)](https://github.com/SeanLee97/BertWordPieceTokenizer.jl)
    * Julia å®ç°æœªçº³å…¥æ¯”è¾ƒèŒƒå›´ã€‚
  
* **BPE**
  * https://github.com/openai/tiktoken

* **SentencePiece**
  * [google/sentencepiece (C++)](https://github.com/google/sentencepiece)



## â­ å†å²è®°å½•

<a href="https://www.star-history.com/#NLPOptimize/flash-tokenizer&Date">

 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=NLPOptimize/flash-tokenizer&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=NLPOptimize/flash-tokenizer&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=NLPOptimize/flash-tokenizer&type=Date" />
 </picture>
</a>


## å‚è€ƒæ–‡çŒ®

* https://medium.com/@techhara/which-bert-tokenizer-is-faster-b832aa978b46
* https://medium.com/@atharv6f_47401/wordpiece-tokenization-a-bpe-variant-73cc48865cbf
* https://www.restack.io/p/transformer-models-bert-answer-fast-berttokenizerfast-cat-ai
* https://medium.com/@anmolkohli/my-notes-on-bert-tokenizer-and-model-98dc22d0b64
* https://nocomplexity.com/documents/fossml/nlpframeworks.html
* https://github.com/martinus/robin-hood-hashing
* https://arxiv.org/abs/2012.15524
* https://github.com/google/highway
